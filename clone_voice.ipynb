{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/suno-ai/bark.git\n",
        "!git clone https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n",
        "!pip install -r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBTrLJr6Yrrj",
        "outputId": "69565376-0ede-46b9-9389-10ae87ed8634"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/suno-ai/bark.git\n",
            "  Cloning https://github.com/suno-ai/bark.git to /tmp/pip-req-build-y2l6pxh5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/suno-ai/bark.git /tmp/pip-req-build-y2l6pxh5\n",
            "  Resolved https://github.com/suno-ai/bark.git to commit 773624d26db84278a55aacae9a16d7b25fbccab8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3 (from suno-bark==0.0.1a0)\n",
            "  Downloading boto3-1.34.64-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting encodec (from suno-bark==0.0.1a0)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting funcy (from suno-bark==0.0.1a0)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (0.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (1.11.4)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (0.15.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (4.66.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (24.0)\n",
            "Collecting botocore<1.35.0,>=1.34.64 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading botocore-1.34.64-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from encodec->suno-bark==0.0.1a0) (2.2.1+cu121)\n",
            "Collecting einops (from encodec->suno-bark==0.0.1a0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->suno-bark==0.0.1a0) (2023.12.25)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->suno-bark==0.0.1a0) (0.4.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.64->boto3->suno-bark==0.0.1a0) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.64->boto3->suno-bark==0.0.1a0) (2.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->suno-bark==0.0.1a0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->suno-bark==0.0.1a0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.64->boto3->suno-bark==0.0.1a0) (1.16.0)\n",
            "Building wheels for collected packages: suno-bark, encodec\n",
            "  Building wheel for suno-bark (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for suno-bark: filename=suno_bark-0.0.1a0-py3-none-any.whl size=2567413 sha256=7fe794df36ec16e4766e85f1388b050e9541f693b07c13f5e19f6394f20b26ba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wvpkteb8/wheels/e6/6d/c2/107ed849afe600f905bb4049a026df3c7c5aa75d86c2721ec7\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45762 sha256=8e5fd18b24666c5df3fea0eba1bd12a8a53eccf0c6cd037459ec9e732d465477\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "Successfully built suno-bark encodec\n",
            "Installing collected packages: funcy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, einops, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, s3transfer, nvidia-cusolver-cu12, boto3, encodec, suno-bark\n",
            "Successfully installed boto3-1.34.64 botocore-1.34.64 einops-0.7.0 encodec-0.1.1 funcy-2.0 jmespath-1.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 s3transfer-0.10.1 suno-bark-0.0.1a0\n",
            "Cloning into 'bark-voice-cloning-HuBERT-quantizer'...\n",
            "remote: Enumerating objects: 1882, done.\u001b[K\n",
            "remote: Counting objects: 100% (247/247), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 1882 (delta 144), reused 215 (delta 124), pack-reused 1635\u001b[K\n",
            "Receiving objects: 100% (1882/1882), 319.75 MiB | 44.89 MiB/s, done.\n",
            "Resolving deltas: 100% (145/145), done.\n",
            "Ignoring soundfile: markers 'platform_system == \"Windows\"' don't match your environment\n",
            "Collecting audiolm-pytorch==1.1.4 (from -r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n",
            "  Downloading audiolm_pytorch-1.1.4-py3-none-any.whl (37 kB)\n",
            "Collecting fairseq (from -r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from -r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (0.20.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 4)) (0.1.99)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 5)) (4.38.2)\n",
            "Requirement already satisfied: encodec in /usr/local/lib/python3.10/dist-packages (from -r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 6)) (0.1.1)\n",
            "Collecting sox (from -r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 8))\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Collecting accelerate (from audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beartype (from audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n",
            "  Downloading beartype-0.17.2-py3-none-any.whl (872 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.4/872.4 kB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: einops>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (0.7.0)\n",
            "Collecting ema-pytorch>=0.2.2 (from audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n",
            "  Downloading ema_pytorch-0.4.3-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (1.3.2)\n",
            "Collecting lion-pytorch (from audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n",
            "  Downloading lion_pytorch-0.1.2-py3-none-any.whl (4.4 kB)\n",
            "Collecting local-attention>=1.8.4 (from audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n",
            "  Downloading local_attention-1.9.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.12 in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (4.66.2)\n",
            "Collecting vector-quantize-pytorch>=1.5.14 (from audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n",
            "  Downloading vector_quantize_pytorch-1.14.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (3.0.9)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (2023.12.25)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n",
            "  Downloading sacrebleu-2.4.1-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitarray (from fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n",
            "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (24.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 5)) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 5)) (0.4.2)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (4.9.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (12.4.99)\n",
            "Collecting einx[torch]>=0.1.3 (from vector-quantize-pytorch>=1.5.14->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n",
            "  Downloading einx-0.1.3.tar.gz (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (2024.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.10/dist-packages (from einx[torch]>=0.1.3->vector-quantize-pytorch>=1.5.14->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12->audiolm-pytorch==1.1.4->-r ./bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime, einx\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11291768 sha256=c5160c7e8f38792f6d232d793d81b696ddc598037e9feb966310b25cef557af3\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=aa4897485d31775d5d881251ea951753a35959ad2f3889572ee7f983c438aa7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "  Building wheel for einx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for einx: filename=einx-0.1.3-py3-none-any.whl size=80072 sha256=6a13d96ecb32a72c3d7863d158798900f36ca9dbfa77e9e9d55ad23a8f62ea46\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/98/b2/ceed882dc5ccb13727cc2b27bb1d0e504599a2dc679a8f3c4d\n",
            "Successfully built fairseq antlr4-python3-runtime einx\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, sox, portalocker, omegaconf, colorama, beartype, sacrebleu, hydra-core, einx, local-attention, lion-pytorch, ema-pytorch, accelerate, vector-quantize-pytorch, fairseq, audiolm-pytorch\n",
            "Successfully installed accelerate-0.28.0 antlr4-python3-runtime-4.8 audiolm-pytorch-1.1.4 beartype-0.17.2 bitarray-2.9.2 colorama-0.4.6 einx-0.1.3 ema-pytorch-0.4.3 fairseq-0.12.2 hydra-core-1.0.7 lion-pytorch-0.1.2 local-attention-1.9.0 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.4.1 sox-1.4.1 vector-quantize-pytorch-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('./bark-voice-cloning-HuBERT-quantizer')"
      ],
      "metadata": {
        "id": "R6JJ6xyigcNc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3EFQS8WqX-l8"
      },
      "outputs": [],
      "source": [
        "from bark.generation import load_codec_model, generate_text_semantic\n",
        "from encodec.utils import convert_audio\n",
        "\n",
        "import torchaudio\n",
        "import torch\n",
        "\n",
        "device = 'cuda' # or 'cpu'\n",
        "model = load_codec_model(use_gpu=True if device == 'cuda' else False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267,
          "referenced_widgets": [
            "5ee473ec632b4fa58a5b60f29706f191",
            "fb2ffa752944477b905a227caaf4d781",
            "1cddf6adc97446128e09068901cf2727",
            "fdb70a8e1516413f9d759914aff9d304",
            "aa70e9c4ad2544529a9264876c21b6b0",
            "9b2f2a19e32b4c298d62c4ab586fdf26",
            "28630f7346dc469c8dc9d366f68eebc1",
            "7df41e10020f41d18e18b477ade389b6",
            "01b149bd447948f399b688b177523874",
            "9d3617d6a941477cb7aac6cbf9642c23",
            "7c754d2c28ac443c907d6937e3941bc6"
          ]
        },
        "id": "3JIdhrXOX-mA",
        "outputId": "c385637f-cf92-4b71-d3b7-25dab3a7077b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading HuBERT base model\n",
            "Downloaded HuBERT\n",
            "Downloading HuBERT custom tokenizer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "quantifier_hubert_base_ls960_14.pth:   0%|          | 0.00/104M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ee473ec632b4fa58a5b60f29706f191"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded tokenizer\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data/models/hubert/tokenizer.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# From https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n",
        "from bark_hubert_quantizer.hubert_manager import HuBERTManager\n",
        "hubert_manager = HuBERTManager()\n",
        "hubert_manager.make_sure_hubert_installed()\n",
        "hubert_manager.make_sure_tokenizer_installed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbQzJSv8X-mA",
        "outputId": "c68b38ab-184d-4745-eed8-d37a02d61d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
          ]
        }
      ],
      "source": [
        "# From https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n",
        "# Load HuBERT for semantic tokens\n",
        "from bark_hubert_quantizer.pre_kmeans_hubert import CustomHubert\n",
        "from bark_hubert_quantizer.customtokenizer import CustomTokenizer\n",
        "\n",
        "# Load the HuBERT model\n",
        "hubert_model = CustomHubert(checkpoint_path='data/models/hubert/hubert.pt').to(device)\n",
        "\n",
        "# Load the CustomTokenizer model\n",
        "tokenizer = CustomTokenizer.load_from_checkpoint('data/models/hubert/tokenizer.pth').to(device)  # Automatically uses the right layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PiagSSlAX-mB",
        "outputId": "300d2905-fcdc-4341-aaaf-e11872c39b85"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to open the input \"audio.wav\" (No such file or directory).\nException raised from get_input_format_context at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_reader/stream_reader.cpp:42 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7a9084281d87 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7a908423275f in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)\nframe #2: <unknown function> + 0x42904 (0x7a906aaca904 in /usr/local/lib/python3.10/dist-packages/torio/lib/libtorio_ffmpeg4.so)\nframe #3: torio::io::StreamingMediaDecoder::StreamingMediaDecoder(std::string const&, std::optional<std::string> const&, std::optional<std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > > const&) + 0x14 (0x7a906aacd304 in /usr/local/lib/python3.10/dist-packages/torio/lib/libtorio_ffmpeg4.so)\nframe #4: <unknown function> + 0x3a58e (0x7a8f993b358e in /usr/local/lib/python3.10/dist-packages/torio/lib/_torio_ffmpeg4.so)\nframe #5: <unknown function> + 0x32147 (0x7a8f993ab147 in /usr/local/lib/python3.10/dist-packages/torio/lib/_torio_ffmpeg4.so)\nframe #6: <unknown function> + 0x15a10e (0x5b116cc2410e in /usr/bin/python3)\nframe #7: _PyObject_MakeTpCall + 0x25b (0x5b116cc1aa7b in /usr/bin/python3)\nframe #8: <unknown function> + 0x168c20 (0x5b116cc32c20 in /usr/bin/python3)\nframe #9: <unknown function> + 0x165087 (0x5b116cc2f087 in /usr/bin/python3)\nframe #10: <unknown function> + 0x150e2b (0x5b116cc1ae2b in /usr/bin/python3)\nframe #11: <unknown function> + 0xf244 (0x7a9094e17244 in /usr/local/lib/python3.10/dist-packages/torchaudio/lib/_torchaudio.so)\nframe #12: _PyObject_MakeTpCall + 0x25b (0x5b116cc1aa7b in /usr/bin/python3)\nframe #13: _PyEval_EvalFrameDefault + 0x6a79 (0x5b116cc13629 in /usr/bin/python3)\nframe #14: _PyObject_FastCallDictTstate + 0xc4 (0x5b116cc19c14 in /usr/bin/python3)\nframe #15: <unknown function> + 0x164a64 (0x5b116cc2ea64 in /usr/bin/python3)\nframe #16: _PyObject_MakeTpCall + 0x1fc (0x5b116cc1aa1c in /usr/bin/python3)\nframe #17: _PyEval_EvalFrameDefault + 0x6a79 (0x5b116cc13629 in /usr/bin/python3)\nframe #18: _PyFunction_Vectorcall + 0x7c (0x5b116cc249fc in /usr/bin/python3)\nframe #19: _PyEval_EvalFrameDefault + 0x6bd (0x5b116cc0d26d in /usr/bin/python3)\nframe #20: _PyFunction_Vectorcall + 0x7c (0x5b116cc249fc in /usr/bin/python3)\nframe #21: _PyEval_EvalFrameDefault + 0x614a (0x5b116cc12cfa in /usr/bin/python3)\nframe #22: _PyFunction_Vectorcall + 0x7c (0x5b116cc249fc in /usr/bin/python3)\nframe #23: _PyEval_EvalFrameDefault + 0x614a (0x5b116cc12cfa in /usr/bin/python3)\nframe #24: <unknown function> + 0x13f9c6 (0x5b116cc099c6 in /usr/bin/python3)\nframe #25: PyEval_EvalCode + 0x86 (0x5b116ccff256 in /usr/bin/python3)\nframe #26: <unknown function> + 0x23ae2d (0x5b116cd04e2d in /usr/bin/python3)\nframe #27: <unknown function> + 0x15ac59 (0x5b116cc24c59 in /usr/bin/python3)\nframe #28: _PyEval_EvalFrameDefault + 0x6bd (0x5b116cc0d26d in /usr/bin/python3)\nframe #29: <unknown function> + 0x177ff0 (0x5b116cc41ff0 in /usr/bin/python3)\nframe #30: _PyEval_EvalFrameDefault + 0x2568 (0x5b116cc0f118 in /usr/bin/python3)\nframe #31: <unknown function> + 0x177ff0 (0x5b116cc41ff0 in /usr/bin/python3)\nframe #32: _PyEval_EvalFrameDefault + 0x2568 (0x5b116cc0f118 in /usr/bin/python3)\nframe #33: <unknown function> + 0x177ff0 (0x5b116cc41ff0 in /usr/bin/python3)\nframe #34: <unknown function> + 0x2557af (0x5b116cd1f7af in /usr/bin/python3)\nframe #35: <unknown function> + 0x1662ca (0x5b116cc302ca in /usr/bin/python3)\nframe #36: _PyEval_EvalFrameDefault + 0x8ac (0x5b116cc0d45c in /usr/bin/python3)\nframe #37: _PyFunction_Vectorcall + 0x7c (0x5b116cc249fc in /usr/bin/python3)\nframe #38: _PyEval_EvalFrameDefault + 0x6bd (0x5b116cc0d26d in /usr/bin/python3)\nframe #39: _PyFunction_Vectorcall + 0x7c (0x5b116cc249fc in /usr/bin/python3)\nframe #40: _PyEval_EvalFrameDefault + 0x8ac (0x5b116cc0d45c in /usr/bin/python3)\nframe #41: <unknown function> + 0x1687f1 (0x5b116cc327f1 in /usr/bin/python3)\nframe #42: PyObject_Call + 0x122 (0x5b116cc33492 in /usr/bin/python3)\nframe #43: _PyEval_EvalFrameDefault + 0x2a27 (0x5b116cc0f5d7 in /usr/bin/python3)\nframe #44: <unknown function> + 0x1687f1 (0x5b116cc327f1 in /usr/bin/python3)\nframe #45: _PyEval_EvalFrameDefault + 0x198c (0x5b116cc0e53c in /usr/bin/python3)\nframe #46: <unknown function> + 0x200175 (0x5b116ccca175 in /usr/bin/python3)\nframe #47: <unknown function> + 0x15ac59 (0x5b116cc24c59 in /usr/bin/python3)\nframe #48: <unknown function> + 0x236bc5 (0x5b116cd00bc5 in /usr/bin/python3)\nframe #49: <unknown function> + 0x2b2572 (0x5b116cd7c572 in /usr/bin/python3)\nframe #50: <unknown function> + 0x14d99b (0x5b116cc1799b in /usr/bin/python3)\nframe #51: _PyEval_EvalFrameDefault + 0x6bd (0x5b116cc0d26d in /usr/bin/python3)\nframe #52: _PyFunction_Vectorcall + 0x7c (0x5b116cc249fc in /usr/bin/python3)\nframe #53: _PyEval_EvalFrameDefault + 0x8ac (0x5b116cc0d45c in /usr/bin/python3)\nframe #54: <unknown function> + 0x200175 (0x5b116ccca175 in /usr/bin/python3)\nframe #55: <unknown function> + 0x15ac59 (0x5b116cc24c59 in /usr/bin/python3)\nframe #56: <unknown function> + 0x236bc5 (0x5b116cd00bc5 in /usr/bin/python3)\nframe #57: <unknown function> + 0x2b2572 (0x5b116cd7c572 in /usr/bin/python3)\nframe #58: <unknown function> + 0x14d99b (0x5b116cc1799b in /usr/bin/python3)\nframe #59: _PyEval_EvalFrameDefault + 0x6bd (0x5b116cc0d26d in /usr/bin/python3)\nframe #60: <unknown function> + 0x1687f1 (0x5b116cc327f1 in /usr/bin/python3)\nframe #61: _PyEval_EvalFrameDefault + 0x6bd (0x5b116cc0d26d in /usr/bin/python3)\nframe #62: <unknown function> + 0x200175 (0x5b116ccca175 in /usr/bin/python3)\nframe #63: <unknown function> + 0x15ac59 (0x5b116cc24c59 in /usr/bin/python3)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e6cf7828b44a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load and pre-process the audio waveform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0maudio_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'audio.wav'\u001b[0m \u001b[0;31m# the audio you want to clone (under 13 seconds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/_backend/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \"\"\"\n\u001b[1;32m    204\u001b[0m         \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/_backend/ffmpeg.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mbuffer_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     ) -> Tuple[torch.Tensor, int]:\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/_backend/ffmpeg.py\u001b[0m in \u001b[0;36mload_audio\u001b[0;34m(src, frame_offset, num_frames, convert, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"vorbis\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ogg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStreamReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_src_stream_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_audio_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mfilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_load_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torio/io/_streaming_media_decoder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, format, option, buffer_size)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_be\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffmpeg_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStreamingMediaDecoderFileObj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_be\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffmpeg_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStreamingMediaDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_be\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_best_audio_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to open the input \"audio.wav\" (No such file or directory).\nException raised from get_input_format_context at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_reader/stream_reader.cpp:42 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7a9084281d87 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7a908423275f in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)\nframe #2: <unknown function> + 0x42904 (0x7a906aaca904 in /usr/local/lib/python3.10/dist-packages/torio/lib/libtorio_ffmpeg4.so)\nframe #3: torio::io::StreamingMediaDecoder::StreamingMediaDecoder(std::string const&, std::optional<std::string> const&, std::optional<std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > > const&) + 0x14 (0x7a906aacd304 in /usr/local/lib/python3.10/dist-packages/torio/lib/libtorio_ffmpeg4.so)\nframe #4: <unknown function> + 0x3a58e (0x7a8f993b358e in /usr/local/lib/python3.10/dist-packages/torio/lib/_torio_ffmpeg4.so)\nframe #5: <unknown function> + 0x32147 (0x7a8f993ab147 in /usr/local/lib/python3.10/dist-packages/torio/lib/_torio_ffmpeg4.so)\nframe #6: <unknown function> + 0x15a10e (0x5b116cc2410e in /usr/bin/python3)\nframe #7: _PyObject_MakeTpCall + 0x25b (0x5b116cc1aa7b in /usr/bin/python3)\nframe #8: <unknown function> + 0x168c20 (0x5b116cc32c20 in /usr/bin/python3)\nframe #9: <unknown function> + 0x165087 (0x5b116cc2f087 in /usr/bin/python3)\nframe #10: <unknown function> + 0x150e2b (0x5b116cc1ae2b in /usr/bin/python3)\nframe #11: <unknown function> + 0xf244 (0x7a9094e17244 in /usr/local/lib/python3.10/dist-packages/torchaudio/lib/_torchaudio.so)\nframe #12: _PyObject_MakeTpCall + 0x25b (0x5b116cc1aa7b in /usr/bin/python3)\nframe #13: _PyEval_EvalFrameDefault + 0x6a79 (0x5b116cc13629 in /usr/bin/python3)\nframe #14: _PyObject_FastCallDictTstate + 0xc4 (0x5b116cc19c14 in /usr/bin/python3)\nframe #15: <unknown function> + 0x164a64 (0x5b116cc2ea64 in /usr/bin/python3)\nframe #16: _PyObject_MakeTpCall + 0x1fc (0x5b116cc1aa1c in /usr/bin/python3)\nframe #17: _PyEval_EvalFrameDefault + 0x6a79 (0x5b116cc13629 in /usr/bin/python3)\nframe #18: _PyFunction_Vectorcall + 0x7c (0x5b116cc249fc in /usr/bin/python3)\nframe #19: _PyEval_EvalFrameDefault + 0x6bd (0x5b116cc0d26d in /usr/bin/python3)\nframe #20: _PyFunction_Vectorcall + 0x7c (0x5b116cc249fc in /usr/bin/python3)\nframe #21: _PyEval_EvalFrameDefault + 0x614a (0x5b116cc12cfa in /usr/bin/python3)\nframe #22: _PyFunction_Vectorcall + 0x7c (0x5b116cc249fc in /usr/bin/python3)\nframe #23: _PyEval_EvalFrameDefault + 0x614a (0x5b116cc12cfa in /usr/bin/python3)\nframe #24: <unknown function> + 0x13f9c6 (0x5b116cc099c6 in /usr/bin/python3)\nframe #25: PyEval_EvalCode + 0x86 (0x5b116ccff256 in /usr/bin/python3)\nframe #26: <unknown function> + 0x23ae2d (0x5b116cd04e2d in /usr/bin/python3)\nframe #27: <unknown function> + 0x15ac59 (0x5b116cc24c59 in /usr/bin/python3)\nframe #28: _PyEval_EvalFrameDefault + 0x6bd (0x5b116cc0d26d in /usr/bin/python3)\nframe #29: <unknown function> + 0x177ff0 (0x5b116cc41ff0 in /usr/bin/python3)\nframe #30: _PyEval_EvalFrameDefault + 0x2568 (0x5b116cc0f118 in /usr/bin/python3)\nframe #31: <unknown function> + 0x177ff0 (0x5b116cc41ff0 in /usr/bin/python3)\nframe #32: _PyEval_EvalFrameDefault + 0x2568 (0x5b116cc0f118 in /usr/bin/python3)\nframe #33: <unknown function> + 0x177ff0 (0x5b116cc41ff0 in /usr/bin/python3)\nframe #34: <unknown function> + 0x2557af (0x5b116cd1f7af in /usr/bin/python3)\nframe #35: <unknown function> + 0x1662ca (0x5b116cc302ca in /usr/bin/python3)\nframe #36: _PyEval_EvalFrameDefault + 0x8ac (0x5b116cc0d45c in /usr/bin/python3)\nframe #37: _PyFunction_Vectorcall + 0x7c (0x5b116cc249fc in /usr/bin/python3)\nframe #38: _PyEval_EvalFrameDefault + 0x6bd (0x5b116cc0d26d in /usr/bin/python3)\nframe #39: _PyFunction_Vectorcall + 0x7c (0x5b116cc249fc in /usr/bin/python3)\nframe #40: _PyEval_EvalFrameDefault + 0x8ac (0x5b116cc0d45c in /usr/bin/python3)\nframe #41: <unknown function> + 0x1687f1 (0x5b116cc327f1 in /usr/bin/python3)\nframe #42: PyObject_Call + 0x122 (0x5b116cc33492 in /usr/bin/python3)\nframe #43: _PyEval_EvalFrameDefault + 0x2a27 (0x5b116cc0f5d7 in /usr/bin/python3)\nframe #44: <unknown function> + 0x1687f1 (0x5b116cc327f1 in /usr/bin/python3)\nframe #45: _PyEval_EvalFrameDefault + 0x198c (0x5b116cc0e53c in /usr/bin/python3)\nframe #46: <unknown function> + 0x200175 (0x5b116ccca175 in /usr/bin/python3)\nframe #47: <unknown function> + 0x15ac59 (0x5b116cc24c59 in /usr/bin/python3)\nframe #48: <unknown function> + 0x236bc5 (0x5b116cd00bc5 in /usr/bin/python3)\nframe #49: <unknown function> + 0x2b2572 (0x5b116cd7c572 in /usr/bin/python3)\nframe #50: <unknown function> + 0x14d99b (0x5b116cc1799b in /usr/bin/python3)\nframe #51: _PyEval_EvalFrameDefault + 0x6bd (0x5b116cc0d26d in /usr/bin/python3)\nframe #52: _PyFunction_Vectorcall + 0x7c (0x5b116cc249fc in /usr/bin/python3)\nframe #53: _PyEval_EvalFrameDefault + 0x8ac (0x5b116cc0d45c in /usr/bin/python3)\nframe #54: <unknown function> + 0x200175 (0x5b116ccca175 in /usr/bin/python3)\nframe #55: <unknown function> + 0x15ac59 (0x5b116cc24c59 in /usr/bin/python3)\nframe #56: <unknown function> + 0x236bc5 (0x5b116cd00bc5 in /usr/bin/python3)\nframe #57: <unknown function> + 0x2b2572 (0x5b116cd7c572 in /usr/bin/python3)\nframe #58: <unknown function> + 0x14d99b (0x5b116cc1799b in /usr/bin/python3)\nframe #59: _PyEval_EvalFrameDefault + 0x6bd (0x5b116cc0d26d in /usr/bin/python3)\nframe #60: <unknown function> + 0x1687f1 (0x5b116cc327f1 in /usr/bin/python3)\nframe #61: _PyEval_EvalFrameDefault + 0x6bd (0x5b116cc0d26d in /usr/bin/python3)\nframe #62: <unknown function> + 0x200175 (0x5b116ccca175 in /usr/bin/python3)\nframe #63: <unknown function> + 0x15ac59 (0x5b116cc24c59 in /usr/bin/python3)\n"
          ]
        }
      ],
      "source": [
        "# Load and pre-process the audio waveform\n",
        "audio_filepath = 'audio.wav' # the audio you want to clone (under 13 seconds)\n",
        "wav, sr = torchaudio.load(audio_filepath)\n",
        "wav = convert_audio(wav, sr, model.sample_rate, model.channels)\n",
        "wav = wav.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTcYamh4X-mC"
      },
      "outputs": [],
      "source": [
        "semantic_vectors = hubert_model.forward(wav, input_sample_hz=model.sample_rate)\n",
        "semantic_tokens = tokenizer.get_token(semantic_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhloNKMdX-mC"
      },
      "outputs": [],
      "source": [
        "# Extract discrete codes from EnCodec\n",
        "with torch.no_grad():\n",
        "    encoded_frames = model.encode(wav.unsqueeze(0))\n",
        "codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1).squeeze()  # [n_q, T]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUasx0WkX-mC"
      },
      "outputs": [],
      "source": [
        "# move codes to cpu\n",
        "codes = codes.cpu().numpy()\n",
        "# move semantic tokens to cpu\n",
        "semantic_tokens = semantic_tokens.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8bYgI6zX-mD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "voice_name = 'output' # whatever you want the name of the voice to be\n",
        "output_path = 'bark/assets/prompts/' + voice_name + '.npz'\n",
        "np.savez(output_path, fine_prompt=codes, coarse_prompt=codes[:2, :], semantic_prompt=semantic_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfzZqU_pX-mD"
      },
      "outputs": [],
      "source": [
        "# That's it! Now you can head over to the generate.ipynb and use your voice_name for the 'history_prompt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJxvfsGsX-mE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEJ_1h9WX-mE"
      },
      "outputs": [],
      "source": [
        "# Heres the generation stuff copy-pasted for convenience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bBRNxwDX-mE"
      },
      "outputs": [],
      "source": [
        "from bark.api import generate_audio\n",
        "from transformers import BertTokenizer\n",
        "from bark.generation import SAMPLE_RATE, preload_models, codec_decode, generate_coarse, generate_fine, generate_text_semantic\n",
        "\n",
        "# Enter your prompt and speaker here\n",
        "text_prompt = \"Hello, my name is Serpy. And, uh — and I like pizza. [laughs]\"\n",
        "voice_name = \"output\" # use your custom voice name here if you have one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbgaRkw-X-mE"
      },
      "outputs": [],
      "source": [
        "# download and load all models\n",
        "preload_models(\n",
        "    text_use_gpu=True,\n",
        "    text_use_small=False,\n",
        "    coarse_use_gpu=True,\n",
        "    coarse_use_small=False,\n",
        "    fine_use_gpu=True,\n",
        "    fine_use_small=False,\n",
        "    codec_use_gpu=True,\n",
        "    force_reload=False,\n",
        "    path=\"models\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WLlPWVAX-mF"
      },
      "outputs": [],
      "source": [
        "# simple generation\n",
        "audio_array = generate_audio(text_prompt, history_prompt=voice_name, text_temp=0.7, waveform_temp=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDpSWJcKX-mF"
      },
      "outputs": [],
      "source": [
        "# generation with more control\n",
        "x_semantic = generate_text_semantic(\n",
        "    text_prompt,\n",
        "    history_prompt=voice_name,\n",
        "    temp=0.7,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        ")\n",
        "\n",
        "x_coarse_gen = generate_coarse(\n",
        "    x_semantic,\n",
        "    history_prompt=voice_name,\n",
        "    temp=0.7,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        ")\n",
        "x_fine_gen = generate_fine(\n",
        "    x_coarse_gen,\n",
        "    history_prompt=voice_name,\n",
        "    temp=0.5,\n",
        ")\n",
        "audio_array = codec_decode(x_fine_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u6r42zwX-mF"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "# play audio\n",
        "Audio(audio_array, rate=SAMPLE_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnGudOD3X-mF"
      },
      "outputs": [],
      "source": [
        "from scipy.io.wavfile import write as write_wav\n",
        "# save audio\n",
        "filepath = \"/output/audio.wav\" # change this to your desired output path\n",
        "write_wav(filepath, SAMPLE_RATE, audio_array)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ee473ec632b4fa58a5b60f29706f191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb2ffa752944477b905a227caaf4d781",
              "IPY_MODEL_1cddf6adc97446128e09068901cf2727",
              "IPY_MODEL_fdb70a8e1516413f9d759914aff9d304"
            ],
            "layout": "IPY_MODEL_aa70e9c4ad2544529a9264876c21b6b0"
          }
        },
        "fb2ffa752944477b905a227caaf4d781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b2f2a19e32b4c298d62c4ab586fdf26",
            "placeholder": "​",
            "style": "IPY_MODEL_28630f7346dc469c8dc9d366f68eebc1",
            "value": "quantifier_hubert_base_ls960_14.pth: 100%"
          }
        },
        "1cddf6adc97446128e09068901cf2727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7df41e10020f41d18e18b477ade389b6",
            "max": 103981977,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01b149bd447948f399b688b177523874",
            "value": 103981977
          }
        },
        "fdb70a8e1516413f9d759914aff9d304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d3617d6a941477cb7aac6cbf9642c23",
            "placeholder": "​",
            "style": "IPY_MODEL_7c754d2c28ac443c907d6937e3941bc6",
            "value": " 104M/104M [00:02&lt;00:00, 79.7MB/s]"
          }
        },
        "aa70e9c4ad2544529a9264876c21b6b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b2f2a19e32b4c298d62c4ab586fdf26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28630f7346dc469c8dc9d366f68eebc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7df41e10020f41d18e18b477ade389b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01b149bd447948f399b688b177523874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d3617d6a941477cb7aac6cbf9642c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c754d2c28ac443c907d6937e3941bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}